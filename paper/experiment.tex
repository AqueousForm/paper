
\section{Results and Discussion}
\label{sec:Results}

In order to evaluate the impacts of different components of our hybrid system, a series of experiments are conducted. We first show the re-projection error of different methods. Then we quantitatively analyze the reconstruction quality using a ground-truth model scanned by an accurate Lidar scanner.  
Finally we show the reconstructed models of human bodies under different pose to demonstrate the robustness of our method.

\xj{Discussion on time.}

\noindent\textbf{Camera Calibration Accuracy.} 
%
The re-projection error describes the accuracy of the calibration system. 
We compute the re-projection and compare it to evaluate the effectiveness of our global calibration step.
%
Using the 2D coordinates of the corners detected in the checkerboard images, we can achieve the 3D space coordinates $\mathbf{P_{c}}$ by triangulation \xj{using what camera parameters?}. 
Then we re-project $\mathbf{P_{c}}$ to each view which the checkerboard can be seen using the extrinsic parameters obtained by different methods and compute the average re-projection error, as shown in Table~\ref{tab:reprojection}.


\begin{table*}
	\centering
	\caption{Average re-projection error (pixels) of each camera using different methods. (a) results by Kalibr~\cite{Maye2013Self}, (b) results by Kalibr ~\cite{Maye2013Self} with our registration step, (c) results by our global calibration method, (d) results by our integrated method. The re-projection error of (c) is the smaller and uniform in each view, while the results of other methods contain the accumulative error and the inconsistence. }
	\label{tab:reprojection}
	\begin{tabular}{lcccccccc}
		\hline
		Methods & Cam 1 & Cam 2 & Cam 3 & Cam 4 & Cam 5 & Cam 6 & Cam 7 & Cam 8\\
		\hline
		(a) Kalibr &4.54 &3.20 &11.16 &10.74 &4.87 &6.75 &3.64 &5.11\\

		(b) Kalibr+ICP &3.75 &4.04 &11.40 &7.91 &6.39 &5.62 &3.39 &5.74\\
		
		(c) SBA   &\textbf{0.32} &\textbf{0.32} &\textbf{0.38}  &\textbf{0.35} &\textbf{0.37} &\textbf{0.40} &\textbf{0.33} &\textbf{0.34} \\
		
		(d) SBA+ICP &0.92 &0.99 &1.58 &2.19 &3.06 &1.79 &2.68 &1.38\\
		\hline
		
	\end{tabular}


\end{table*}


The reprojection error of the proposed global calibration method is the smaller \xj{smallest?} among different methods, which proves that the global optimization is quite effective. 
Although the registration step makes the model closer to the ground truth, it leads to bigger reprojection error. That is because the aim of the registration step is to minimize the error caused by the inaccurate depth estimation, but not to optimize the camera parameters.


\noindent\textbf{Reconstruction Quality.}
%\xj{Explain why do you need this experiment.}
The final goal of our system is to achieve a high-quality reconstruction model, we quantitatively compare the results reconstructed by different methods.
%
We generate a ground-truth model by scanning a plaster model of a human head using a 3D laser scanner with the scanning error smaller than 0.04 mm \xj{in what depth range?}. 
%
The model is placed in the center of our multi-camera system and the RGB and depth images of it can be obtained. \xj{how do you know where is the center? }
%We consider the accurate mesh as the ground truth and compare it with the reconstructed 3D model using different methods.
We compute the L2 distances of the fused point clouds to the ground-truth mesh for different variants of our method. 
For each point $\vb{p}$ in the reconstructed point cloud, we search for its nearest point $\vb{q}$ on the mesh, and compute the distance $\|\vb{p}-\vb{q}\|$. 
%
The average error is listed in Table~\ref{fig:distance}. \xj{show a chart?} 
As we can see, the reconstructed model combining SBA and registration has the smallest error, which proves that it can achieve a high-quality model.
We also show the distribution histogram of the error using different extrinsic parameters in Figure~\ref{fig:histogram}. 
Similarly, the result of our method has the most accurate result.
\xj{Combine the distribution figure with table as two charts.}

\begin{figure*}[ht]
  \centering
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=4cm]{image/dis_1.png}
\end{minipage}
}%
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=4cm]{image/dis_2.png}
\end{minipage}
}
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=4cm]{image/dis_3.png}
\end{minipage}
}
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=4cm]{image/dis_4.png}
\end{minipage}
}
\caption{The distribution histogram of the L2 distances of the point cloud reconstructed using different methods to the ground truth. (a) results by Kalibr ~\cite{Maye2013Self}, (b) results by Kalibr ~\cite{Maye2013Self} with our registration step, (c) results by our global calibration method, (d) results by our integrated method. The number of the points with small distance increases obviously after the optimization and registration step we proposed.}
\label{fig:histogram}
\end{figure*}

\noindent \textbf{More Reconstructed Models.}
%
We reconstruct the 3D point clouds of a human body standing in the center of our multi-camera system using various methods.  We mark the point cloud in different views with different colors to show the quality of the fusion results. Figure~\ref{fig:pointcloud} shows the results which demonstrate our algorithm. As we can see, the model reconstructed by our hybrid system has the highest quality. 

\xj{Show at least three groups of results, in different human pose.}

\begin{figure*}[ht]
  \centering
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=2.5cm]{image/pc_1.png}
\end{minipage}
}%
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=2.5cm]{image/pc_2.png}
\end{minipage}
}
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=2.5cm]{image/pc_3.png}
\end{minipage}
}
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=2.5cm]{image/pc_4.png}
\end{minipage}
}
\caption{The reconstruction results of the back of a human using various methods.(a) results by Kalibr ~\cite{Maye2013Self}, (b) results by Kalibr ~\cite{Maye2013Self} with our registration step, (c) results by our global calibration method, (d) results by our integrated method. We render the point clouds with different colors to distinguish which view the point clouds belong to. The point clouds in result (a) are distinctly separated from other views, as the pink and green views cover the whole surface of the model. Result (b) becomes a little better while the green view still covers the right side of the body. The point clouds align quite well in result (c) with small blemishes, the azure view is inside the model. (d) shows a well-aligned model. }
\label{fig:pointcloud}
\end{figure*}


\begin{figure*}[ht]
  \centering
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=2.5cm]{image/pc_1_1.png}
\end{minipage}
}%
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=2.5cm]{image/pc_2_1.png}
\end{minipage}
}
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=2.5cm]{image/pc_3_1.png}
\end{minipage}
}
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=2.5cm]{image/pc_4_1.png}
\end{minipage}
}
\caption{The reconstruction results of the back of a human using various methods.(a) results by Kalibr ~\cite{Maye2013Self}, (b) results by Kalibr ~\cite{Maye2013Self} with our registration step, (c) results by our global calibration method, (d) results by our integrated method.}
\label{fig:pointcloud}
\end{figure*}

\begin{figure*}[ht]
  \centering
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=2.5cm]{image/pc_1_2.png}
\end{minipage}
}%
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=2.5cm]{image/pc_2_2.png}
\end{minipage}
}
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=2.5cm]{image/pc_3_2.png}
\end{minipage}
}
\subfigure[]{
\begin{minipage}[c]{.22\linewidth}
\centering
  \includegraphics[width=2.5cm]{image/pc_4_2.png}
\end{minipage}
}
\caption{The reconstruction results of the back of a human using various methods.(a) results by Kalibr ~\cite{Maye2013Self}, (b) results by Kalibr ~\cite{Maye2013Self} with our registration step, (c) results by our global calibration method, (d) results by our integrated method.}
\label{fig:pointcloud}
\end{figure*}
\section{conclusion}
We present an efficient system integrating the multi-camera calibration and point cloud registration. By a global bundle adjustment, we reduce the accumulative error and the inconsistence caused by the pairwise camera pose estimation, and achieve a set of accurate extrinsic parameters with less reprojection error. With the point cloud registration, we minimize the error from the depth estimation and achieve a high-quality 3D model. Our calibration algorithm has been tested on both reprojection error and ground truth data. The experimental results has proved that the two steps of our system are both necessary and effective, and a more accuracy model can be reconstructed using our method.
\begin{table}
	\centering
	\caption{The distance between the point cloud and the ground truth. The distance (in centimeters )of the point cloud to the mesh of the plaster model computed by four different methods. (a) results by Kalibr ~\cite{Maye2013Self}, (b) results by Kalibr ~\cite{Maye2013Self} with our registration step, (c) results by our global calibration method, (d) results by our integrated method.}
	\label{tab:distance}
	\begin{tabular}{lcccc}
		\hline
		Methods & Mean &Standard deviation\\
		\hline
		(a) &0.9542 &0.7240\\

		(b) &0.8243 &0.6376\\
		
		(c) &0.6408 &0.5072\\
		
		(d) &0.5811 &0.4650\\
		\hline
		
	\end{tabular}
\label{fig:distance}
\end{table}


