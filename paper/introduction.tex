% Template for ICME 2018 paper; to be used with:
%          spconf.sty  - ICASSP/ICIP/ICME LaTeX style file, and
%          IEEEbib.bst - IEEE bibliography style file.
% --------------------------------------------------------------------------
\documentclass{article}
\usepackage{spconf,amsmath,epsfig}
\usepackage{graphicx}
\usepackage{subfigure}
\pagestyle{empty}


\begin{document}\sloppy

% Example definitions.
% --------------------
\def\x{{\mathbf x}}
\def\L{{\cal L}}


% Title.
% ------
\title{A Hybrid System Integrating Calibration and Registration for Accurate 3D Reconstruction}
%
% Single address.
% ---------------
\name{Zhehan Song, Xuejin Chen}
\address{University of Science and Technology of China}


\maketitle


%
\begin{abstract}
With the development of virtual and augmented reality, indoor 3D reconstruction based on multi-camera systems has become increasingly popular recently. The quality of the reconstruction relies on many factors, including the multi-view camera parameters and the depth estimation in single view. To improve the final 3D model, we replace the traditional pairwise relations of both camera and model fusion to a global framework. First, a global bundle adjustment is adopted to increase the accuracy of camera pose estimation. We use checkerboard corners to optimize the camera extrinsic parameters globally which are obtained by pairwise camera calibration methods. Second, a point cloud registration is used to map the inaccurate depth to a 3D model. We use ICP (Iterative Closest Point) to register the point clouds in different views and use the transformation from ICP to minimize the error caused by the depth estimation. The experimental results show our reconstructed results are precise and the effect of adjustment is promising.
\end{abstract}
%
\begin{keywords}
Multi-camera System, 3D reconstruction, camera calibration, point cloud registration
\end{keywords}
%
\section{Introduction}

Real-time indoor 3D reconstructions from multiple views have become more and more prevalent recent years~\cite{dou2016fusion4d,orts2016holoportation}. Multi-camera systems using RGBD cameras have many advantages such as a wider horizon compared with the systems based on single camera, and are widely used in many kinds of applications. However, both the intrinsic and extrinsic parameters of the multi-camera systems are required to be calibrated accurately in order to achieve a high-quality and real-time 3D reconstruction of an entire object like people or furniture with less error.

For a single camera system, the accurate intrinsic parameters can be achieved by many internal calibration methods or toolboxes~\cite{zhang2000flexible,zhang2004camera}. Many efficient methods have also been developed for the calibration of different types of multi-camera calibration. One widely proposed approach for the multi-camera calibration is to use special calibration objects, such as  patterns, rig or similar. Li~\cite{Li2013A} proposed a toolbox to calibrate the system which uses a feature descriptor based calibration pattern. The pattern can be automatically detected even if the pattern is partially seen in an image. The toolbox yields good results especially on the systems with few cameras (three or four) with minimal overlapping fields of view. Zhao~\cite{zhao2008practical} proposed an algorithm based on 1D objects which works well on a triple camera system. The algorithm integrates the rank-4 factorization with the standard 1D camera calibration method and is much more convenient than the plane-based algorithm. Svoboda~\cite{svoboda2005convenient} gives a method only required any bright-spot object like a laser pointer. Waving the object which can be easily detected in each image through the working space is the only work requested. Kalibr~\cite{Maye2013Self} is a free toolbox that solves the multiple camera calibration problems. It can get a good estimate but requires that neighbouring cameras have overlapping fields of view. However, if the system contains many cameras and they do not share the same overlapping fields of view, the calibration process should be simply repeated for each pair of cameras.

Another kind of methods which is commonly used is self-calibration. These methods do the calibration using the constraints and correspondences from the images without any special calibration objects. Bundler~\cite{snavely2006photo} is a structure-from-motion toolbox using the unordered images captured from different views. The pose of all cameras can be estimated by the 3D reconstruction. It uses SIFT keypoint detector~\cite{lowe2004distinctive} which works well on the outdoor scenery but weak on indoor cases because of the lack of the features. Vasconcelos~\cite{vasconcelos2012minimal} proposed a solution to calibrate a camera with two other calibrated cameras using independent pairwise point correspondences. Bushnevskiy~\cite{bushnevskiy2016multicamera} present a novel approach for the estimation of the geometry of the multi-camera system. The algorithm enforce constraints arising from the visible epipoles and is especially suitable for dome-like indoor cases.

All these methods use RGB images to calibrate the multi-camera system and achieve good results. However, not only RGB cameras, other kinds of sensors are also widely used in 3D reconstruction system nowadays, like Near Infra-Red cameras (NIR). If there are such cameras within the system used to estimate the depth, the error of the final result of the 3D reconstruction not only comes from the calibration of the RGB cameras but also from the depth estimation. Many research have been done on the depth estimation~\cite{scharstein,Bleyer2011PatchMatch}, whereas the error can not be eliminated entirely. How to minimize the error of the whole reconstruction to achieve an accurate model is a problem.

In this paper, we present an efficient algorithm to optimize the extrinsic camera parameters for indoor 3D reconstruction. To avoid from accumulative error caused by the repetitive calibration for each pair of cameras, we use a global camera calibration method and optimize all the camera parameters consistently. Furthermore, we use the point cloud registration method to adjust the result of the reconstruction. This can effectively decrease the error result from the depth estimation and obtain a high-quality 3D reconstruction.





% References should be produced using the bibtex program from suitable
% BiBTeX files (here: strings, refs, manuals). The IEEEbib.bst bibliography
% style file from IEEE produces unsorted bibliography list.
% -------------------------------------------------------------------------
\bibliographystyle{IEEEbib}
\bibliography{icme2018template}

\end{document}
